{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osJI_Ww1RT_2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model.\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')"
      ],
      "metadata": {
        "id": "vBlGbLfjRvEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_classes(scores, class_names, top_n=5):\n",
        "    mean_scores = scores.mean(axis=0)\n",
        "    top_indices = np.argsort(mean_scores)[::-1][:top_n]\n",
        "    top_classes = [(class_names[i], mean_scores[i]) for i in top_indices]\n",
        "    return top_classes\n",
        "\n",
        "def guess_voicemail_type(top_classes):\n",
        "    human_keywords = ['Speech', 'Male speech', 'Female speech', 'Child speech']\n",
        "    machine_keywords = ['Telephone', 'DTMF tone', 'Dial tone', 'Synthesizer', 'Beep']\n",
        "\n",
        "    top_class_names = [name for name, score in top_classes]\n",
        "\n",
        "    if any(k in ' '.join(top_class_names) for k in human_keywords):\n",
        "        return \"Likely Human Voicemail (Human voice detected)\"\n",
        "\n",
        "    if any(k in ' '.join(top_class_names) for k in machine_keywords):\n",
        "        return \"Likely Machine Voicemail (Machine sounds detected)\"\n",
        "\n",
        "    return \"Voicemail type unclear\""
      ],
      "metadata": {
        "id": "aV86ZHCiVOVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores, embeddings, spectrogram = model(waveform)\n",
        "\n",
        "top_classes = get_top_classes(scores.numpy(), class_names, top_n=5)\n",
        "print(\"Top predicted classes and scores:\")\n",
        "for name, score in top_classes:\n",
        "    print(f\"{name}: {score:.3f}\")\n",
        "\n",
        "voicemail_guess = guess_voicemail_type(top_classes)\n",
        "print(voicemail_guess)"
      ],
      "metadata": {
        "id": "fqsaU8rGVQEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores, embeddings, spectrogram = model(waveform)\n",
        "\n",
        "top_classes = get_top_classes(scores.numpy(), class_names, top_n=5)\n",
        "print(\"Top predicted classes and scores:\")\n",
        "for name, score in top_classes:\n",
        "    print(f\"{name}: {score:.3f}\")\n",
        "\n",
        "voicemail_guess = guess_voicemail_type(top_classes)\n",
        "print(voicemail_guess)"
      ],
      "metadata": {
        "id": "9QiAoQlCVQJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports and model loading code...\n",
        "\n",
        "def get_top_classes(scores, class_names, top_n=5):\n",
        "    mean_scores = scores.mean(axis=0)\n",
        "    top_indices = mean_scores.argsort()[-top_n:][::-1]\n",
        "    top = [(class_names[i], mean_scores[i]) for i in top_indices]\n",
        "    return top\n",
        "\n",
        "def guess_voicemail_type(top_classes):\n",
        "    # Example heuristic:\n",
        "    keywords_human = ['Speech', 'Human voice', 'Conversation']\n",
        "    keywords_machine = ['Machine', 'Beep', 'Ringtone']\n",
        "\n",
        "    for name, score in top_classes:\n",
        "        if any(k in name for k in keywords_human):\n",
        "            return \"This audio likely contains human voice.\"\n",
        "        if any(k in name for k in keywords_machine):\n",
        "            return \"This audio likely contains machine voicemail or automated message.\"\n",
        "    return \"Unable to determine voicemail type.\"\n",
        "\n",
        "# Load audio, preprocess, normalize waveform...\n",
        "scores, embeddings, spectrogram = model(waveform)\n",
        "\n",
        "top_classes = get_top_classes(scores.numpy(), class_names, top_n=5)\n",
        "print(\"Top predicted classes and scores:\")\n",
        "for name, score in top_classes:\n",
        "    print(f\"{name}: {score:.3f}\")\n",
        "\n",
        "voicemail_guess = guess_voicemail_type(top_classes)\n",
        "print(voicemail_guess)"
      ],
      "metadata": {
        "id": "VGjEktzHVQNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import csv\n",
        "import scipy.signal\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# Load the YAMNet model from TensorFlow Hub\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "\n",
        "# Load class names for the model\n",
        "def class_names_from_csv(class_map_csv_text):\n",
        "    class_names = []\n",
        "    with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            class_names.append(row['display_name'])\n",
        "    return class_names\n",
        "\n",
        "class_map_path = model.class_map_path().numpy()\n",
        "class_names = class_names_from_csv(class_map_path)\n",
        "\n",
        "# Resample waveform to 16kHz if needed\n",
        "def ensure_sample_rate(original_sample_rate, waveform, desired_sample_rate=16000):\n",
        "    if original_sample_rate != desired_sample_rate:\n",
        "        desired_length = int(round(float(len(waveform)) / original_sample_rate * desired_sample_rate))\n",
        "        waveform = scipy.signal.resample(waveform, desired_length)\n",
        "    return desired_sample_rate, waveform\n",
        "\n",
        "# Function to get top classes from scores\n",
        "def get_top_classes(scores, class_names, top_n=5):\n",
        "    mean_scores = np.mean(scores, axis=0)\n",
        "    top_indices = mean_scores.argsort()[-top_n:][::-1]\n",
        "    return [(class_names[i], mean_scores[i]) for i in top_indices]\n",
        "\n",
        "# Function to guess voicemail type based on predicted classes\n",
        "def guess_voicemail_type(top_classes):\n",
        "    keywords_human = ['Speech', 'Conversation', 'Narration', 'Male speech', 'Female speech']\n",
        "    keywords_machine = ['Telephone', 'Beep', 'Ring', 'Alarm', 'Computer', 'Electronic']\n",
        "\n",
        "    for class_name, score in top_classes:\n",
        "        if any(k in class_name for k in keywords_human):\n",
        "            return \"Detected: Human voice or voicemail\"\n",
        "        if any(k in class_name for k in keywords_machine):\n",
        "            return \"Detected: Machine voicemail or alert\"\n",
        "    return \"Unable to determine voicemail type.\"\n",
        "\n",
        "# Main prediction function\n",
        "def predict_audio_file(audio_path):\n",
        "    sample_rate, wav_data = wavfile.read(audio_path, 'rb')\n",
        "    sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)\n",
        "\n",
        "    # Normalize waveform to [-1.0, 1.0]\n",
        "    waveform = wav_data / tf.int16.max\n",
        "\n",
        "    # Run the model\n",
        "    scores, embeddings, spectrogram = model(waveform)\n",
        "\n",
        "    # Get top predicted classes\n",
        "    top_classes = get_top_classes(scores.numpy(), class_names, top_n=5)\n",
        "\n",
        "    print(f\"Top predicted classes and scores for '{audio_path}':\")\n",
        "    for name, score in top_classes:\n",
        "        print(f\"{name}: {score:.3f}\")\n",
        "\n",
        "    # Guess voicemail type\n",
        "    voicemail_guess = guess_voicemail_type(top_classes)\n",
        "    print(voicemail_guess)\n",
        "\n",
        "# Example usage:\n",
        "# Replace 'your_audio.wav' with your audio file path\n",
        "audio_file_path = '/content/20250430-194418-17328631663.wav'\n",
        "predict_audio_file(audio_file_path)"
      ],
      "metadata": {
        "id": "tpmz-riWVQah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import csv\n",
        "import scipy.signal\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# Load the YAMNet model from TensorFlow Hub\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "\n",
        "# Load class names for the model\n",
        "def class_names_from_csv(class_map_csv_text):\n",
        "    class_names = []\n",
        "    with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            class_names.append(row['display_name'])\n",
        "    return class_names\n",
        "\n",
        "class_map_path = model.class_map_path().numpy()\n",
        "class_names = class_names_from_csv(class_map_path)\n",
        "\n",
        "# Resample waveform to 16kHz if needed\n",
        "def ensure_sample_rate(original_sample_rate, waveform, desired_sample_rate=16000):\n",
        "    if original_sample_rate != desired_sample_rate:\n",
        "        desired_length = int(round(float(len(waveform)) / original_sample_rate * desired_sample_rate))\n",
        "        waveform = scipy.signal.resample(waveform, desired_length)\n",
        "    return desired_sample_rate, waveform\n",
        "\n",
        "# Function to get top classes from scores\n",
        "def get_top_classes(scores, class_names, top_n=5):\n",
        "    mean_scores = np.mean(scores, axis=0)\n",
        "    top_indices = mean_scores.argsort()[-top_n:][::-1]\n",
        "    return [(class_names[i], mean_scores[i]) for i in top_indices]\n",
        "\n",
        "# Improved function to guess voicemail type based on predicted classes\n",
        "def guess_voicemail_type(top_classes):\n",
        "    class_scores = {name.lower(): score for name, score in top_classes}\n",
        "\n",
        "    speech_score = class_scores.get('speech', 0)\n",
        "    telephone_score = class_scores.get('telephone', 0)\n",
        "    beep_score = class_scores.get('beep', 0)\n",
        "    dial_tone_score = class_scores.get('dial tone', 0)\n",
        "    ringtone_score = class_scores.get('ringtone', 0)\n",
        "    modem_score = class_scores.get('modem', 0)\n",
        "    fax_score = class_scores.get('fax', 0)\n",
        "\n",
        "    speech_threshold = 0.3\n",
        "    machine_sound_threshold = 0.1\n",
        "    telephone_threshold = 0.05\n",
        "\n",
        "    if speech_score > speech_threshold:\n",
        "        if (telephone_score > telephone_threshold or\n",
        "            beep_score > machine_sound_threshold or\n",
        "            dial_tone_score > machine_sound_threshold or\n",
        "            ringtone_score > machine_sound_threshold or\n",
        "            modem_score > machine_sound_threshold or\n",
        "            fax_score > machine_sound_threshold):\n",
        "            return \"Detected: Human voicemail\"\n",
        "        else:\n",
        "            return \"Detected: Human voice\"\n",
        "    else:\n",
        "        if (beep_score > machine_sound_threshold or\n",
        "            dial_tone_score > machine_sound_threshold or\n",
        "            ringtone_score > machine_sound_threshold or\n",
        "            modem_score > machine_sound_threshold or\n",
        "            fax_score > machine_sound_threshold):\n",
        "            return \"Detected: Machine voicemail\"\n",
        "        else:\n",
        "            return \"Unable to determine voicemail type.\"\n",
        "\n",
        "# Main prediction function\n",
        "def predict_audio_file(audio_path):\n",
        "    sample_rate, wav_data = wavfile.read(audio_path, 'rb')\n",
        "    sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)\n",
        "\n",
        "    waveform = wav_data / tf.int16.max\n",
        "\n",
        "    scores, embeddings, spectrogram = model(waveform)\n",
        "\n",
        "    top_classes = get_top_classes(scores.numpy(), class_names, top_n=10)\n",
        "\n",
        "    print(f\"Top predicted classes and scores for '{audio_path}':\")\n",
        "    for name, score in top_classes:\n",
        "        print(f\"{name}: {score:.3f}\")\n",
        "\n",
        "    voicemail_guess = guess_voicemail_type(top_classes)\n",
        "    print(voicemail_guess)\n",
        "\n",
        "# Example usage:\n",
        "audio_file_path = '/content/20250430-194418-17328631663.wav'\n",
        "predict_audio_file(audio_file_path)"
      ],
      "metadata": {
        "id": "9iQEYMrfYzEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import csv\n",
        "import scipy.signal\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# Load the YAMNet model from TensorFlow Hub\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "\n",
        "# Load class names for the model\n",
        "def class_names_from_csv(class_map_csv_text):\n",
        "    class_names = []\n",
        "    with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            class_names.append(row['display_name'])\n",
        "    return class_names\n",
        "\n",
        "class_map_path = model.class_map_path().numpy()\n",
        "class_names = class_names_from_csv(class_map_path)\n",
        "\n",
        "# Resample waveform to 16kHz if needed\n",
        "def ensure_sample_rate(original_sample_rate, waveform, desired_sample_rate=16000):\n",
        "    if original_sample_rate != desired_sample_rate:\n",
        "        desired_length = int(round(float(len(waveform)) / original_sample_rate * desired_sample_rate))\n",
        "        waveform = scipy.signal.resample(waveform, desired_length)\n",
        "    return desired_sample_rate, waveform\n",
        "\n",
        "# Function to get top classes from scores\n",
        "def get_top_classes(scores, class_names, top_n=5):\n",
        "    mean_scores = np.mean(scores, axis=0)\n",
        "    top_indices = mean_scores.argsort()[-top_n:][::-1]\n",
        "    return [(class_names[i], mean_scores[i]) for i in top_indices]\n",
        "\n",
        "# Improved function to guess voicemail type based on predicted classes\n",
        "def guess_voicemail_type(top_classes):\n",
        "    class_scores = {name.lower(): score for name, score in top_classes}\n",
        "\n",
        "    speech_score = class_scores.get('speech', 0)\n",
        "    telephone_score = class_scores.get('telephone', 0)\n",
        "    beep_score = class_scores.get('beep', 0)\n",
        "    dial_tone_score = class_scores.get('dial tone', 0)\n",
        "    ringtone_score = class_scores.get('ringtone', 0)\n",
        "    modem_score = class_scores.get('modem', 0)\n",
        "    fax_score = class_scores.get('fax', 0)\n",
        "\n",
        "    speech_threshold = 0.3\n",
        "    machine_sound_threshold = 0.1\n",
        "    telephone_threshold = 0.05\n",
        "\n",
        "    if speech_score > speech_threshold:\n",
        "        if (telephone_score > telephone_threshold or\n",
        "            beep_score > machine_sound_threshold or\n",
        "            dial_tone_score > machine_sound_threshold or\n",
        "            ringtone_score > machine_sound_threshold or\n",
        "            modem_score > machine_sound_threshold or\n",
        "            fax_score > machine_sound_threshold):\n",
        "            return \"Detected: Human voicemail\"\n",
        "        else:\n",
        "            return \"Detected: Human voice\"\n",
        "    else:\n",
        "        if (beep_score > machine_sound_threshold or\n",
        "            dial_tone_score > machine_sound_threshold or\n",
        "            ringtone_score > machine_sound_threshold or\n",
        "            modem_score > machine_sound_threshold or\n",
        "            fax_score > machine_sound_threshold):\n",
        "            return \"Detected: Machine voicemail\"\n",
        "        else:\n",
        "            return \"Unable to determine voicemail type.\"\n",
        "\n",
        "# Main prediction function\n",
        "def predict_audio_file(audio_path):\n",
        "    sample_rate, wav_data = wavfile.read(audio_path, 'rb')\n",
        "    sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)\n",
        "\n",
        "    waveform = wav_data / tf.int16.max\n",
        "\n",
        "    scores, embeddings, spectrogram = model(waveform)\n",
        "\n",
        "    top_classes = get_top_classes(scores.numpy(), class_names, top_n=10)\n",
        "\n",
        "    print(f\"Top predicted classes and scores for '{audio_path}':\")\n",
        "    for name, score in top_classes:\n",
        "        print(f\"{name}: {score:.3f}\")\n",
        "\n",
        "    voicemail_guess = guess_voicemail_type(top_classes)\n",
        "    print(voicemail_guess)\n",
        "\n",
        "# Example usage:\n",
        "audio_file_path = '/content/20250422-211457-12692086177.wav'\n",
        "predict_audio_file(audio_file_path)"
      ],
      "metadata": {
        "id": "hUPZ9sJRZBSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import csv\n",
        "import scipy.signal\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# Load the YAMNet model from TensorFlow Hub\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "\n",
        "# Load class names for the model\n",
        "def class_names_from_csv(class_map_csv_text):\n",
        "    class_names = []\n",
        "    with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            class_names.append(row['display_name'])\n",
        "    return class_names\n",
        "\n",
        "class_map_path = model.class_map_path().numpy()\n",
        "class_names = class_names_from_csv(class_map_path)\n",
        "\n",
        "# Resample waveform to 16kHz if needed\n",
        "def ensure_sample_rate(original_sample_rate, waveform, desired_sample_rate=16000):\n",
        "    if original_sample_rate != desired_sample_rate:\n",
        "        desired_length = int(round(float(len(waveform)) / original_sample_rate * desired_sample_rate))\n",
        "        waveform = scipy.signal.resample(waveform, desired_length)\n",
        "    return desired_sample_rate, waveform\n",
        "\n",
        "# Function to get top classes from scores\n",
        "def get_top_classes(scores, class_names, top_n=5):\n",
        "    mean_scores = np.mean(scores, axis=0)\n",
        "    top_indices = mean_scores.argsort()[-top_n:][::-1]\n",
        "    return [(class_names[i], mean_scores[i]) for i in top_indices]\n",
        "\n",
        "# Improved function to guess voicemail type based on predicted classes and scores\n",
        "def guess_voicemail_type(top_classes):\n",
        "    # Convert list of tuples to dict for easy lookup\n",
        "    class_score_dict = {name: score for name, score in top_classes}\n",
        "\n",
        "    speech_score = class_score_dict.get('Speech', 0)\n",
        "    speech_synth_score = class_score_dict.get('Speech synthesizer', 0)\n",
        "    telephone_score = class_score_dict.get('Telephone', 0)\n",
        "    beep_score = class_score_dict.get('Beep', 0)\n",
        "    ring_score = class_score_dict.get('Ring', 0)\n",
        "    computer_score = class_score_dict.get('Computer', 0)\n",
        "    electronic_score = class_score_dict.get('Electronic', 0)\n",
        "\n",
        "    # Thresholds - you can tune these based on your dataset\n",
        "    speech_threshold = 0.4\n",
        "    machine_threshold = 0.1\n",
        "\n",
        "    if speech_score > speech_threshold and all(class_score_dict.get(k, 0) < machine_threshold for k in ['Telephone', 'Beep', 'Ring', 'Computer', 'Electronic']):\n",
        "        return \"Detected: Human voice\"\n",
        "    elif speech_score > speech_threshold and any(class_score_dict.get(k, 0) >= machine_threshold for k in ['Telephone', 'Beep', 'Ring', 'Computer', 'Electronic']):\n",
        "        return \"Detected: Human voicemail\"\n",
        "    elif any(class_score_dict.get(k, 0) >= speech_threshold for k in ['Telephone', 'Beep', 'Ring', 'Computer', 'Electronic', 'Speech synthesizer']):\n",
        "        return \"Detected: Machine voicemail\"\n",
        "    else:\n",
        "        return \"Unable to determine voicemail type.\"\n",
        "\n",
        "# Main prediction function\n",
        "def predict_audio_file(audio_path):\n",
        "    sample_rate, wav_data = wavfile.read(audio_path, 'rb')\n",
        "    sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)\n",
        "\n",
        "    # Normalize waveform to [-1.0, 1.0]\n",
        "    waveform = wav_data / tf.int16.max\n",
        "\n",
        "    # Run the model\n",
        "    scores, embeddings, spectrogram = model(waveform)\n",
        "\n",
        "    # Get top predicted classes\n",
        "    top_classes = get_top_classes(scores.numpy(), class_names, top_n=10)\n",
        "\n",
        "    print(f\"Top predicted classes and scores for '{audio_path}':\")\n",
        "    for name, score in top_classes:\n",
        "        print(f\"{name}: {score:.3f}\")\n",
        "\n",
        "    # Guess voicemail type\n",
        "    voicemail_guess = guess_voicemail_type(top_classes)\n",
        "    print(voicemail_guess)\n",
        "\n",
        "# Example usage:\n",
        "# Replace 'your_audio.wav' with your actual audio file path\n",
        "audio_file_path = '/content/20250422-211457-12692086177.wav'\n",
        "predict_audio_file(audio_file_path)"
      ],
      "metadata": {
        "id": "tBLPYzTnZfVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import csv\n",
        "import scipy.signal\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# Load YAMNet model\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "\n",
        "# Load class names from YAMNet\n",
        "def class_names_from_csv(csv_path):\n",
        "    class_names = []\n",
        "    with tf.io.gfile.GFile(csv_path) as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            class_names.append(row['display_name'])\n",
        "    return class_names\n",
        "\n",
        "class_map_path = model.class_map_path().numpy()\n",
        "class_names = class_names_from_csv(class_map_path)\n",
        "\n",
        "# Ensure 16kHz sample rate\n",
        "def ensure_sample_rate(sr, waveform, target_sr=16000):\n",
        "    if sr != target_sr:\n",
        "        desired_length = int(round(float(len(waveform)) / sr * target_sr))\n",
        "        waveform = scipy.signal.resample(waveform, desired_length)\n",
        "        sr = target_sr\n",
        "    return sr, waveform\n",
        "\n",
        "# Get top N classes from prediction scores\n",
        "def get_top_classes(scores, class_names, top_n=5):\n",
        "    mean_scores = np.mean(scores, axis=0)\n",
        "    top_indices = mean_scores.argsort()[-top_n:][::-1]\n",
        "    return [(class_names[i], mean_scores[i]) for i in top_indices]\n",
        "\n",
        "# Heuristic function to determine voicemail type\n",
        "def guess_voicemail_type(top_classes):\n",
        "    class_score_dict = {name: score for name, score in top_classes}\n",
        "\n",
        "    speech = class_score_dict.get('Speech', 0)\n",
        "    synth = class_score_dict.get('Speech synthesizer', 0)\n",
        "    telephone = class_score_dict.get('Telephone', 0)\n",
        "    beep = class_score_dict.get('Beep', 0)\n",
        "    computer = class_score_dict.get('Computer keyboard', 0)\n",
        "    narration = class_score_dict.get('Narration, monologue', 0)\n",
        "    conversation = class_score_dict.get('Conversation', 0)\n",
        "\n",
        "    # Rules\n",
        "    if synth > 0.1 or (telephone + beep + computer) > 0.2:\n",
        "        return \"Detected: Machine voicemail\"\n",
        "    elif speech > 0.4 and (narration > 0.05 or conversation > 0.05):\n",
        "        return \"Detected: Human voicemail\"\n",
        "    elif speech > 0.6 and synth < 0.05:\n",
        "        return \"Detected: Human voice\"\n",
        "    else:\n",
        "        return \"Unable to determine voicemail type.\"\n",
        "\n",
        "# Main function\n",
        "def predict_audio_file(audio_path):\n",
        "    sr, wav_data = wavfile.read(audio_path)\n",
        "    sr, wav_data = ensure_sample_rate(sr, wav_data)\n",
        "    waveform = wav_data / np.iinfo(np.int16).max\n",
        "\n",
        "    # In case of stereo audio, use only one channel\n",
        "    if len(waveform.shape) > 1:\n",
        "        waveform = waveform[:, 0]\n",
        "\n",
        "    scores, embeddings, spectrogram = model(waveform)\n",
        "\n",
        "    top_classes = get_top_classes(scores.numpy(), class_names, top_n=5)\n",
        "\n",
        "    print(f\"\\nTop predicted classes and scores for '{audio_path}':\")\n",
        "    for name, score in top_classes:\n",
        "        print(f\"{name}: {score:.3f}\")\n",
        "\n",
        "    voicemail_type = guess_voicemail_type(top_classes)\n",
        "    print(voicemail_type)\n",
        "\n",
        "# Example usage\n",
        "audio_file_path = '/content/20250422-211457-12692086177.wav'  # Replace this with your .wav file path\n",
        "predict_audio_file(audio_file_path)"
      ],
      "metadata": {
        "id": "JIhLyUVjbrj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wC8V7Xkxbrwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UuvK_Ydobr1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code is for just testing on google dataset which are applied yamnet model for prediction which are predict on it correctly.**bold text**"
      ],
      "metadata": {
        "id": "3PTzlAE7ZCbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile"
      ],
      "metadata": {
        "id": "pao4_Qu3ZhVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model.\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')"
      ],
      "metadata": {
        "id": "LZFIyy1sZiRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the name of the class with the top score when mean-aggregated across frames.\n",
        "def class_names_from_csv(class_map_csv_text):\n",
        "  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
        "  class_names = []\n",
        "  with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "      class_names.append(row['display_name'])\n",
        "\n",
        "  return class_names\n",
        "\n",
        "class_map_path = model.class_map_path().numpy()\n",
        "class_names = class_names_from_csv(class_map_path)"
      ],
      "metadata": {
        "id": "t38V2XU5R4I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ensure_sample_rate(original_sample_rate, waveform,\n",
        "                       desired_sample_rate=16000):\n",
        "  \"\"\"Resample waveform if required.\"\"\"\n",
        "  if original_sample_rate != desired_sample_rate:\n",
        "    desired_length = int(round(float(len(waveform)) /\n",
        "                               original_sample_rate * desired_sample_rate))\n",
        "    waveform = scipy.signal.resample(waveform, desired_length)\n",
        "  return desired_sample_rate, waveform"
      ],
      "metadata": {
        "id": "v3deDEcaR59R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://storage.googleapis.com/audioset/speech_whistling2.wav"
      ],
      "metadata": {
        "id": "CoJEjjX0SFAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://storage.googleapis.com/audioset/miaow_16k.wav"
      ],
      "metadata": {
        "id": "8hyr4o68SFEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wav_file_name = 'speech_whistling2.wav'\n",
        "wav_file_name = 'miaow_16k.wav'\n",
        "sample_rate, wav_data = wavfile.read(wav_file_name, 'rb')\n",
        "sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)\n",
        "\n",
        "# Show some basic information about the audio.\n",
        "duration = len(wav_data)/sample_rate\n",
        "print(f'Sample rate: {sample_rate} Hz')\n",
        "print(f'Total duration: {duration:.2f}s')\n",
        "print(f'Size of the input: {len(wav_data)}')\n",
        "\n",
        "# Listening to the wav file.\n",
        "Audio(wav_data, rate=sample_rate)"
      ],
      "metadata": {
        "id": "yjnCK2tOSFH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waveform = wav_data / tf.int16.max"
      ],
      "metadata": {
        "id": "fmhZ0Qg4SXA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the model, check the output.\n",
        "scores, embeddings, spectrogram = model(waveform)"
      ],
      "metadata": {
        "id": "Ogt_4tb1SZWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_np = scores.numpy()\n",
        "spectrogram_np = spectrogram.numpy()\n",
        "infered_class = class_names[scores_np.mean(axis=0).argmax()]\n",
        "print(f'The main sound is: {infered_class}')"
      ],
      "metadata": {
        "id": "Wa2-8xPtSjXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the waveform.\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(waveform)\n",
        "plt.xlim([0, len(waveform)])\n",
        "\n",
        "# Plot the log-mel spectrogram (returned by the model).\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.imshow(spectrogram_np.T, aspect='auto', interpolation='nearest', origin='lower')\n",
        "\n",
        "# Plot and label the model output scores for the top-scoring classes.\n",
        "mean_scores = np.mean(scores, axis=0)\n",
        "top_n = 10\n",
        "top_class_indices = np.argsort(mean_scores)[::-1][:top_n]\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.imshow(scores_np[:, top_class_indices].T, aspect='auto', interpolation='nearest', cmap='gray_r')\n",
        "\n",
        "# patch_padding = (PATCH_WINDOW_SECONDS / 2) / PATCH_HOP_SECONDS\n",
        "# values from the model documentation\n",
        "patch_padding = (0.025 / 2) / 0.01\n",
        "plt.xlim([-patch_padding-0.5, scores.shape[0] + patch_padding-0.5])\n",
        "# Label the top_N classes.\n",
        "yticks = range(0, top_n, 1)\n",
        "plt.yticks(yticks, [class_names[top_class_indices[x]] for x in yticks])\n",
        "_ = plt.ylim(-0.5 + np.array([top_n, 0]))"
      ],
      "metadata": {
        "id": "SMCzV0AgSvtb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}